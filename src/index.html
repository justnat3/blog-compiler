<h1># Creating a Blog Compiler (Static Pages)</h1><p>For Blog compilation I am using python with no external packages other than the standard library. Just like making a programming language we have the following steps.</p><ol><li value='1'>. Parsing(in this case no tree is needed)</li><li value='1'>. Compilation</li><li value='1'>. Profit</li></ol><p>So how does this all fit together?</p><h1>## The Parser</h1><p>The Parser is really both the lexer & the parser combo'd together, in tandom this</p><p>class will parse and compile a single page</p><p>it all starts here, at render(). Which is a function the program calls at the begining of __main__()</p><p>this will change in the future, however- it is what it is currently.</p><pre>
&gt; def render() -&gt; None: ...
		|
		&gt; def parse_page(self) -&gt; object: ...
</pre><p>render() will first call parse_page() and it looks traditional lex'ing code.</p><ol><li value='1'>. Figure out what it is and tokenize it</li><li value='1'>. Add it to a list of tokens(no tree part)</li></ol><p>This is so that later on we can interpret the tokens context</p><p>i'm starting to think that I should have just done an AST</p><pre>
def parse_page(self) -&gt; object:
	while True:

		# detecting the bounds of the line
		# if our cursor exceeds the bounds of the file_buff we can exit the parser
		if self.cursor &gt;= len(self.file_buff):
			return

		char = self.file_buff[self.cursor]

		# I think it would be nice to honor newlines
		# in theory you could get around this by using comments
		if char == "\n" or char == "\r":
			self.line += 1
			self.add_token("newline", "\n")

		# grabbing full headings
		elif char == "#":

			# returns how much of a heading there is
			heading = self.grab_string()
			size = heading.count("#")

			heading = heading[size + 1 :]

			self.add_token("atx_heading", heading, size)
		...
	...
...
</pre><p>The process is pretty simple, and it is not entirely stable yet. </p><p>We have a look for every character in a file buffer </p><pre>
        while True:

            tmp_cursor = self.cursor + self.lookahead_ptr

            # if grab_string happens to touch the edge of the file buffer
            if tmp_cursor &gt;= len(self.file_buff):

                # grab the last char
                result += self.file_buff[-1]

                # give the resulting string back
                self.cursor = (tmp_cursor) - 1
                return result

				... # more parser code
</pre>